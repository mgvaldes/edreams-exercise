{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned data\n",
    "data_type = 'clean_enriched'\n",
    "data = pd.read_csv(data_type + '_train.csv', sep=';', decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data to separate 'y' and 'X'.\n",
    "y = data['EXTRA_BAGGAGE']\n",
    "\n",
    "# Drop target variable from X DataFrame\n",
    "X = data.drop('EXTRA_BAGGAGE', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We'll apply nested cross-validation in order to avoid the possible bias of applying \n",
    "# cross-validation combined with grid-search to perform parameter tuning.\n",
    "\n",
    "# We'll use nested cross-validation over several classification methods in order to\n",
    "# obtain their generalization score and choose the one with highest score. After this,\n",
    "# we'll perform a simple cross-validation with grid-search in order to obtain the \n",
    "# best configuration of hyper-parameters for this algorithm. Finally we'll train \n",
    "# the model with all the training data and the hyper-parameter configuration that\n",
    "# yield the best results.\n",
    "\n",
    "# variace: it removes useless variables with variace equal to zero.\n",
    "# scaler: standardizes each column to have mean equal to zero and variance equal to 1, \n",
    "# in order to give same importance to variables with different measurement units.\n",
    "lr_pipe = Pipeline([('variance', VarianceThreshold()),\n",
    "                    ('scaler', StandardScaler()),\n",
    "                    ('lr', LogisticRegression(class_weight='balanced', random_state=621473))])\n",
    "\n",
    "param_grid = dict()\n",
    "param_grid['lr__C'] = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "\n",
    "inner_cv = StratifiedKFold(n_splits=10, random_state=975428)\n",
    "outer_cv = StratifiedKFold(n_splits=10, random_state=248733)\n",
    "\n",
    "gs_cv = GridSearchCV(lr_pipe, param_grid=param_grid, n_jobs=-1, scoring='f1_weighted', cv=inner_cv, verbose=10)\n",
    "\n",
    "lr_nested_cv_f1_scores = cross_val_score(gs_cv, X, y, cv=outer_cv, verbose=10)\n",
    "\n",
    "joblib.dump(lr_nested_cv_f1_scores, data_type + '_lr_nested_cv_f1_scores.pkl', compress=1)\n",
    "\n",
    "print(\"##### Generalization F1 Score: mean =\", np.mean(lr_nested_cv_f1_scores), \"std =\", np.std(lr_nested_cv_f1_scores))\n",
    "print()\n",
    "\n",
    "##### Encoded:   Generalization F1 Score: mean = 0.663232566525 std = 0.00577941758843\n",
    "##### Binarized  Generalization F1 Score: mean = 0.662300707325 std = 0.00639698194352\n",
    "##### Enriched:  Generalization F1 Score: mean = 0.668949634197 std = 0.00667454322097\n",
    "##### Enriched2: Generalization F1 Score: mean = 0.668859982719 std = 0.00605384828548"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "linear_svm_pipe = Pipeline([('variance', VarianceThreshold()),\n",
    "                            ('scaler', StandardScaler()),\n",
    "                            ('linear_svm', LinearSVC(penalty='l1', dual=False, random_state=123456, class_weight='balanced'))])\n",
    "\n",
    "param_grid = dict()\n",
    "param_grid['linear_svm__C'] = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "\n",
    "inner_cv = StratifiedKFold(n_splits=10, random_state=975428)\n",
    "outer_cv = StratifiedKFold(n_splits=10, random_state=248733)\n",
    "\n",
    "gs_cv = GridSearchCV(linear_svm_pipe, param_grid=param_grid, n_jobs=-1, scoring='f1_weighted', cv=inner_cv, verbose=10)\n",
    "\n",
    "linear_svm_nested_cv_f1_scores = cross_val_score(gs_cv, X, y, cv=outer_cv, verbose=10)\n",
    "\n",
    "joblib.dump(linear_svm_nested_cv_f1_scores, data_type + '_linear_svm_nested_cv_f1_scores.pkl', compress=1)\n",
    "\n",
    "print(\"##### Generalization F1 Score: mean =\", np.mean(linear_svm_nested_cv_f1_scores), \"std =\", np.std(linear_svm_nested_cv_f1_scores))\n",
    "print()\n",
    "\n",
    "##### Enriched: Generalization F1 Score: mean = 0.667330992787 std = 0.00671589397452"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf_pipe = Pipeline([('variance', VarianceThreshold()),\n",
    "                    ('scaler', StandardScaler()),\n",
    "                    ('rf', RandomForestClassifier(max_features='sqrt', oob_score=True, random_state=573146, class_weight='balanced'))])\n",
    "\n",
    "param_grid = dict()\n",
    "param_grid['rf__n_estimators'] = list(range(200, 2300, 300))\n",
    "# param_grid['rf__max_depth'] = [10, 20, 30]\n",
    "# param_grid['rf__min_samples_leaf'] = [50, 60, 70, 80, 90, 100]\n",
    "\n",
    "\n",
    "inner_cv = StratifiedKFold(n_splits=10, random_state=975428)\n",
    "outer_cv = StratifiedKFold(n_splits=10, random_state=248733)\n",
    "\n",
    "gs_cv = GridSearchCV(rf_pipe, param_grid=param_grid, n_jobs=-1, scoring='f1_weighted', cv=inner_cv, verbose=10)\n",
    "\n",
    "rf_nested_cv_f1_scores = cross_val_score(gs_cv, X, y, cv=outer_cv, verbose=10)\n",
    "\n",
    "joblib.dump(rf_nested_cv_f1_scores, data_type + '_rf_nested_cv_f1_scores.pkl', compress=1)\n",
    "\n",
    "print(\"##### Generalization F1 Score: mean =\", np.mean(rf_nested_cv_f1_scores), \"std =\", np.std(rf_nested_cv_f1_scores))\n",
    "print()\n",
    "\n",
    "##### Encoded: Generalization F1 Score: mean = 0.687527970451 std = 0.00504951880128\n",
    "##### Enriched: Generalization F1 Score: mean = 0.786092676427 std = 0.0114704698622"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot boxplot of nested cross-validation scores.\n",
    "def plot_cv_scores(cv_scores):\n",
    "    print(cv_scores)\n",
    "    print()\n",
    "    \n",
    "    sns.set_style(\"whitegrid\")\n",
    "    \n",
    "    ax = sns.boxplot(x=cv_scores, orient=\"v\")\n",
    "    \n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_nested_cv_f1_scores = joblib.load(data_type + '_lr_nested_cv_f1_scores.pkl')\n",
    "\n",
    "plot_cv_scores(lr_nested_cv_f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_variable_ranking(model, model_type, column_names):\n",
    "    if model_type == \"rf\":\n",
    "        importance = model.feature_importances_\n",
    "        importance = pd.DataFrame(importance, index=column_names, columns=[\"Importance\"])\n",
    "        importance[\"Std\"] = np.std([tree.feature_importances_ for tree in model.estimators_], axis=0)\n",
    "        \n",
    "        x = range(importance.shape[0])\n",
    "        y = importance.ix[:, 0]        \n",
    "        yerr = importance.ix[:, 1]\n",
    "        \n",
    "        plt.bar(x, y, yerr=yerr, align=\"center\")\n",
    "        plt.xticks(range(len(column_names)), column_names)\n",
    "        plt.show()\n",
    "    elif model_type == \"lr\":\n",
    "        importance = model.coef_\n",
    "        importance = pd.DataFrame(importance, index=column_names, columns=[\"Importance\"])\n",
    "        \n",
    "        x = range(importance.shape[0])\n",
    "        y = importance.ix[:, 0]        \n",
    "        \n",
    "        plt.bar(x, y, align=\"center\")\n",
    "        plt.xticks(range(len(column_names)), column_names)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_lr_pipe = Pipeline([('variance', VarianceThreshold()),\n",
    "                    ('scaler', StandardScaler()),\n",
    "                    ('pca', PCA(random_state=554197)),\n",
    "                    ('lr', LogisticRegression(class_weight='balanced', random_state=621473))])\n",
    "\n",
    "param_grid = dict()\n",
    "param_grid['lr__C'] = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "param_grid['pca__n_components'] = list(range(2, 14, 2))\n",
    "\n",
    "inner_cv = StratifiedKFold(n_splits=10, random_state=975428)\n",
    "outer_cv = StratifiedKFold(n_splits=10, random_state=248733)\n",
    "\n",
    "gs_cv = GridSearchCV(pca_lr_pipe, param_grid=param_grid, n_jobs=-1, scoring='f1_weighted', cv=inner_cv, verbose=10)\n",
    "\n",
    "pca_lr_nested_cv_f1_scores = cross_val_score(gs_cv, X, y, cv=outer_cv, verbose=10)\n",
    "\n",
    "joblib.dump(pca_lr_nested_cv_f1_scores, data_type + '_pca_lr_nested_cv_f1_scores.pkl', compress=1)\n",
    "\n",
    "print(\"##### Generalization F1 Score: mean =\", np.mean(pca_lr_nested_cv_f1_scores), \"std =\", np.std(pca_lr_nested_cv_f1_scores))\n",
    "print\n",
    "\n",
    "##### Encoded:   Generalization F1 Score: mean = 0.660731584574 std = 0.00561434867445\n",
    "##### Binarized: Generalization F1 Score: mean = 0.655650138449 std = 0.00599611460643\n",
    "##### Enriched:  Generalization F1 Score: mean = 0.667960467816 std = 0.00757189854774"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_lr_nested_cv_f1_scores = joblib.load(data_type + '_pca_lr_nested_cv_f1_scores.pkl')\n",
    "\n",
    "plot_cv_scores(pca_lr_nested_cv_f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pca_rf_pipe = Pipeline([('variance', VarianceThreshold()),\n",
    "                        ('scaler', StandardScaler()),\n",
    "                        ('pca', PCA(random_state=554197)),\n",
    "                        ('rf', RandomForestClassifier(max_features='sqrt', oob_score=True, random_state=573146, class_weight='balanced'))])\n",
    "\n",
    "param_grid = dict()\n",
    "param_grid['rf__n_estimators'] = list(range(200, 2300, 300))\n",
    "param_grid['pca__n_components'] = list(range(2, 14, 2))\n",
    "\n",
    "inner_cv = StratifiedKFold(n_splits=10, random_state=975428)\n",
    "outer_cv = StratifiedKFold(n_splits=10, random_state=248733)\n",
    "\n",
    "gs_cv = GridSearchCV(pca_rf_pipe, param_grid=param_grid, n_jobs=-1, scoring='f1_weighted', cv=inner_cv, verbose=10)\n",
    "\n",
    "pca_rf_nested_cv_f1_scores = cross_val_score(gs_cv, X, y, cv=outer_cv, verbose=10)\n",
    "\n",
    "joblib.dump(pca_rf_nested_cv_f1_scores, data_type + '_pca_rf_nested_cv_f1_scores.pkl', compress=1)\n",
    "\n",
    "print(\"##### Generalization F1 Score: mean =\", np.mean(pca_rf_nested_cv_f1_scores), \"std =\", np.std(pca_rf_nested_cv_f1_scores))\n",
    "\n",
    "##### Generalization F1 Score: mean = 0.774613129297 std = 0.00935455148606"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_rf_nested_cv_f1_scores = joblib.load(data_type + '_pca_rf_nested_cv_f1_scores.pkl')\n",
    "\n",
    "plot_cv_scores(pca_rf_nested_cv_f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rfe_lr_pipe = Pipeline([('variance', VarianceThreshold()),\n",
    "                    ('scaler', StandardScaler()),\n",
    "                    ('rfe', RFE(LogisticRegression(class_weight='balanced', random_state=348744), step=4)),\n",
    "                    ('lr', LogisticRegression(class_weight='balanced', random_state=621473))])\n",
    "\n",
    "param_grid = dict()\n",
    "param_grid['lr__C'] = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "param_grid['rfe__n_features_to_select'] = list(range(5, 18, 5))\n",
    "param_grid['rfe__estimator__C'] = [0.1, 1, 10]\n",
    "\n",
    "inner_cv = StratifiedKFold(n_splits=10, random_state=975428)\n",
    "outer_cv = StratifiedKFold(n_splits=10, random_state=248733)\n",
    "\n",
    "gs_cv = GridSearchCV(rfe_lr_pipe, param_grid=param_grid, n_jobs=-1, scoring='f1_weighted', cv=inner_cv, verbose=10)\n",
    "\n",
    "rfe_lr_nested_cv_f1_scores = cross_val_score(gs_cv, X, y, cv=outer_cv, verbose=10)\n",
    "\n",
    "joblib.dump(rfe_lr_nested_cv_f1_scores, data_type + '_rfe_lr_nested_cv_f1_scores.pkl', compress=1)\n",
    "\n",
    "print(\"##### Generalization F1 Score: mean =\", np.mean(rfe_lr_nested_cv_f1_scores), \"std =\", np.std(rfe_lr_nested_cv_f1_scores))\n",
    "print()\n",
    "\n",
    "##### Encoded:   Generalization F1 Score: mean = 0.681933347276 std = 0.0138063133181\n",
    "##### Binarized: Generalization F1 Score: mean = 0.661206281182 std = 0.00693543250238\n",
    "##### Enriched:  Generalization F1 Score: mean = 0.685667061666 std = 0.00621622857699"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_lr_nested_cv_f1_scores = joblib.load(data_type + '_rfe_lr_nested_cv_f1_scores.pkl')\n",
    "\n",
    "plot_cv_scores(rfe_lr_nested_cv_f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_rf_pipe = Pipeline([('variance', VarianceThreshold()),\n",
    "                        ('scaler', StandardScaler()),\n",
    "                        ('rfe', RFE(LogisticRegression(class_weight='balanced', random_state=348744), step=4)),\n",
    "                        ('rf', RandomForestClassifier(max_features='sqrt', oob_score=True, random_state=573146, class_weight='balanced'))])\n",
    "\n",
    "param_grid = dict()\n",
    "param_grid['rf__n_estimators'] = list(range(200, 2300, 300))\n",
    "param_grid['rfe__n_features_to_select'] = list(range(5, 18, 5))\n",
    "param_grid['rfe__estimator__C'] = [0.1, 1, 10]\n",
    "\n",
    "inner_cv = StratifiedKFold(n_splits=10, random_state=975428)\n",
    "outer_cv = StratifiedKFold(n_splits=10, random_state=248733)\n",
    "\n",
    "gs_cv = GridSearchCV(rfe_lr_pipe, param_grid=param_grid, n_jobs=-1, scoring='f1_weighted', cv=inner_cv, verbose=10)\n",
    "\n",
    "rfe_rf_nested_cv_f1_scores = cross_val_score(gs_cv, X, y, cv=outer_cv, verbose=10)\n",
    "\n",
    "joblib.dump(rfe_rf_nested_cv_f1_scores, data_type + '_rfe_rf_nested_cv_f1_scores.pkl', compress=1)\n",
    "\n",
    "print(\"##### Generalization F1 Score: mean =\", np.mean(rfe_rf_nested_cv_f1_scores), \"std =\", np.std(rfe_rf_nested_cv_f1_scores))\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
