{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import locale\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "\n",
    "from datetime import datetime\n",
    "from locale import atof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define function that transforms date into value corresponding to number of week in year \n",
    "# that it belongs to.\n",
    "def day_to_week_of_year(date_to_transform):\n",
    "    return datetime.strptime(date_to_transform + \"/2017\", '%d/%B/%Y').isocalendar()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv('train.csv', sep=';', decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# See data column names.\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# See how many missing values the dataset has.\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Since there are missing values only in variable 'DEVICE' and they are very few we'll \n",
    "# just remove them. If there were much more we could use imputation methods to fill this\n",
    "# missing values.\n",
    "data = data[pd.notnull(data['DEVICE'])]\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# See distribution of classes in target variable.\n",
    "data['EXTRA_BAGGAGE'].value_counts()\n",
    "\n",
    "# Classes are imbalanced. There are much more samples belonging to the 'False' class than \n",
    "# to the 'True' class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Review date variables: 'TIMESTAMP', 'DEPARTURE' and 'ARRIVAL'\n",
    "print(data['TIMESTAMP'][0:5])\n",
    "print(data['DEPARTURE'][0:5])\n",
    "print(data['ARRIVAL'][0:5])\n",
    "\n",
    "# All three date variables have the same format 'day_number/month_name'.\n",
    "# We'll transform these values to numeric values corresponding to number \n",
    "# of week in year that the date belongs to.\n",
    "\n",
    "data['TIMESTAMP'] = data['TIMESTAMP'].apply(day_to_week_of_year)\n",
    "data['DEPARTURE'] = data['DEPARTURE'].apply(day_to_week_of_year)\n",
    "data['ARRIVAL'] = data['ARRIVAL'].apply(day_to_week_of_year)\n",
    "\n",
    "print(data['TIMESTAMP'][0:5])\n",
    "print(data['DEPARTURE'][0:5])\n",
    "print(data['ARRIVAL'][0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Transform string variables 'WEBSITE', 'DEVICE', 'HAUL_TYPE', 'TRIP_TYPE' and 'PRODUCT' \n",
    "# to categorical using LabelEncoder.\n",
    "# IMPORTANT: form 'WEBSITE' variable, we are not sure, all levels that this categorical \n",
    "# variable can take, arein the train.csv dataset.\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "print(data['WEBSITE'].dtype)\n",
    "data['WEBSITE'] = pd.Series(label_encoder.fit_transform(data['WEBSITE'])).values\n",
    "print(data['WEBSITE'][0:5])\n",
    "\n",
    "print(data['DEVICE'].dtype)\n",
    "data['DEVICE'] = pd.Series(label_encoder.fit_transform(data['DEVICE'])).values\n",
    "print(data['DEVICE'][0:5])\n",
    "\n",
    "print(data['HAUL_TYPE'].dtype)\n",
    "data['HAUL_TYPE'] = pd.Series(label_encoder.fit_transform(data['HAUL_TYPE'])).values\n",
    "print(data['HAUL_TYPE'][0:5])\n",
    "\n",
    "print(data['TRIP_TYPE'].dtype)\n",
    "data['TRIP_TYPE'] = pd.Series(label_encoder.fit_transform(data['TRIP_TYPE'])).values\n",
    "print(data['TRIP_TYPE'][0:5])\n",
    "\n",
    "print(data['PRODUCT'].dtype)\n",
    "data['PRODUCT'] = pd.Series(label_encoder.fit_transform(data['PRODUCT'])).values\n",
    "print(data['PRODUCT'][0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Transform string variables 'WEBSITE', 'DEVICE', 'HAUL_TYPE', 'TRIP_TYPE' and 'PRODUCT' \n",
    "# to categorical using LabelEncoder.\n",
    "# IMPORTANT: form 'WEBSITE' variable, we are not sure, all levels that this categorical \n",
    "# variable can take, arein the train.csv dataset.\n",
    "\n",
    "# Won't binarize 'WEBSITE' variable because it has too many levels.\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "print(data['WEBSITE'].dtype)\n",
    "data['WEBSITE'] = pd.Series(label_encoder.fit_transform(data['WEBSITE'])).values\n",
    "print(data['WEBSITE'][0:5])\n",
    "\n",
    "label_encoder = LabelBinarizer()\n",
    "\n",
    "print(data['DEVICE'].dtype)\n",
    "print(data['DEVICE'].shape)\n",
    "print(data['DEVICE'][0:5])\n",
    "encoder_result = label_encoder.fit_transform(data['DEVICE'])\n",
    "device_columns = [\"DEVICE_\" + str(bin_class) for bin_class in label_encoder.classes_]\n",
    "data_device = pd.DataFrame(encoder_result, columns=device_columns)\n",
    "print(\"data device shape:\", data_device.shape)\n",
    "print(data_device[0:5])\n",
    "\n",
    "print(\"data shape:\", data.shape)\n",
    "print(\"new device columns:\", len(device_columns))\n",
    "data = data.drop('DEVICE', 1)\n",
    "data = data.reset_index(drop=True)\n",
    "print(\"data shape:\", data.shape)\n",
    "data = pd.concat([data, data_device], axis=1)\n",
    "data = data.reset_index(drop=True)\n",
    "print(\"new data shape:\", data.shape)\n",
    "print(data[device_columns][0:5])\n",
    "print()\n",
    "\n",
    "print(data['HAUL_TYPE'].dtype)\n",
    "print(data['HAUL_TYPE'].shape)\n",
    "print(data['HAUL_TYPE'][0:5])\n",
    "encoder_result = label_encoder.fit_transform(data['HAUL_TYPE'])\n",
    "haul_type_columns = [\"HAUL_TYPE_\" + str(bin_class) for bin_class in label_encoder.classes_]\n",
    "data_haul_type = pd.DataFrame(encoder_result, columns=haul_type_columns)\n",
    "print(\"data haul_type shape:\", data_haul_type.shape)\n",
    "print(data_haul_type[0:5])\n",
    "\n",
    "print(\"data shape:\", data.shape)\n",
    "print(\"new haul_type columns:\", len(haul_type_columns))\n",
    "data = data.drop('HAUL_TYPE', 1)\n",
    "data = data.reset_index(drop=True)\n",
    "print(\"data shape:\", data.shape)\n",
    "data = pd.concat([data, data_haul_type], axis=1)\n",
    "data = data.reset_index(drop=True)\n",
    "print(\"new data shape:\", data.shape)\n",
    "print(data[haul_type_columns][0:5])\n",
    "print()\n",
    "\n",
    "print(data['TRIP_TYPE'].dtype)\n",
    "print(data['TRIP_TYPE'].shape)\n",
    "print(data['TRIP_TYPE'][0:5])\n",
    "encoder_result = label_encoder.fit_transform(data['TRIP_TYPE'])\n",
    "trip_type_columns = [\"TRIP_TYPE_\" + str(bin_class) for bin_class in label_encoder.classes_]\n",
    "data_trip_type = pd.DataFrame(encoder_result, columns=trip_type_columns)\n",
    "print(\"data trip_type shape:\", data_trip_type.shape)\n",
    "print(data_trip_type[0:5])\n",
    "\n",
    "print(\"data shape:\", data.shape)\n",
    "print(\"new trip_type columns:\", len(trip_type_columns))\n",
    "data = data.drop('TRIP_TYPE', 1)\n",
    "data = data.reset_index(drop=True)\n",
    "print(\"data shape:\", data.shape)\n",
    "data = pd.concat([data, data_trip_type], axis=1)\n",
    "data = data.reset_index(drop=True)\n",
    "print(\"new data shape:\", data.shape)\n",
    "print(data[trip_type_columns][0:5])\n",
    "print()\n",
    "\n",
    "print(data['PRODUCT'].dtype)\n",
    "print(data['PRODUCT'].shape)\n",
    "print(data['PRODUCT'][0:5])\n",
    "encoder_result = label_encoder.fit_transform(data['PRODUCT'])\n",
    "data_product = pd.Series(encoder_result[:, 0], name='PRODUCT')\n",
    "print(\"data product shape:\", data_product.shape)\n",
    "print(data_product[0:5])\n",
    "\n",
    "print(\"data shape:\", data.shape)\n",
    "data = data.drop('PRODUCT', 1)\n",
    "data = data.reset_index(drop=True)\n",
    "print(\"data shape:\", data.shape)\n",
    "data = pd.concat([data, data_product], axis=1)\n",
    "data = data.reset_index(drop=True)\n",
    "print(\"new data shape:\", data.shape)\n",
    "print(data['PRODUCT'][0:5])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ['ID', 'TIMESTAMP', 'WEBSITE', 'GDS', 'DEPARTURE', 'ARRIVAL', 'ADULTS',\n",
    "#  'CHILDREN', 'INFANTS', 'TRAIN', 'HAUL_TYPE', 'DISTANCE', 'DEVICE',\n",
    "#  'TRIP_TYPE', 'PRODUCT', 'SMS', 'EXTRA_BAGGAGE', 'NO_GDS']\n",
    "\n",
    "# Check all integer variables 'GDS', 'NO_GDS', 'ADULTS', 'CHILDREN' and 'INFANTS', have \n",
    "# their corresponding dtype in the pandas DataFrame.\n",
    "print(data['GDS'].dtype)\n",
    "print(data['NO_GDS'].dtype)\n",
    "print(data['ADULTS'].dtype)\n",
    "print(data['CHILDREN'].dtype)\n",
    "print(data['INFANTS'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check all boolean variables 'TRAIN', 'SMS' and 'EXTRA_BAGGAGE' have their corresponding \n",
    "# dtype in the pandas DataFrame.\n",
    "print(data['TRAIN'].dtype)\n",
    "print(data['SMS'].dtype)\n",
    "print(data['EXTRA_BAGGAGE'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check float variable 'DISTANCE' has it's corresponding dtype in the pandas DataFrame.\n",
    "print(data['DISTANCE'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop 'ID' variable since it is useless.\n",
    "data = data.drop('ID', 1)\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store 'clean' dataset into new .csv file\n",
    "# data.to_csv('clean_train.csv', index=False, sep=';')\n",
    "data.to_csv('clean_binarized_train.csv', index=False, sep=';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
